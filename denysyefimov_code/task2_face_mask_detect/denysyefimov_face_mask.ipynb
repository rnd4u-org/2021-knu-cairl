{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копія записника \"Untitled2.ipynb\"",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "38meempNFVDV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "935faf38-4b76-44a6-e37e-800502b2fea0"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import tensorflow as tf\r\n",
        "from  tensorflow.keras.models import load_model\r\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n",
        "input_path = 'path'\r\n",
        "output_path = 'path'\r\n",
        "\r\n",
        "\r\n",
        "print(\"Done!\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYzcH9QN-JKv"
      },
      "source": [
        "**After we have imported all the necessary libraries and specified the path for the data, we will declare several variables for working with photos.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhc9IKEm-ejc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "507a74a3-08ad-45e1-b4ba-125f1ffab3cb"
      },
      "source": [
        "IMG_SIZE = (160, 160)\r\n",
        "BATCH_SIZE = 32\r\n",
        "epochs=10\r\n",
        "tuning_epochs=8\r\n",
        "learning_rate=0.0001\r\n",
        "validation_koef = 5\r\n",
        "\r\n",
        "print(\"Done!\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6keEXHSbAIuo"
      },
      "source": [
        "**Now let's compose our train and validation dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Opm0F9jkAPO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f547ef4-3838-4717-d64d-bd19a59e2a18"
      },
      "source": [
        "train_dataset = image_dataset_from_directory(input_path,\r\n",
        "                                             shuffle=True,\r\n",
        "                                             subset='training',\r\n",
        "                                             seed=1,\r\n",
        "                                             validation_split=0.2,\r\n",
        "                                             batch_size=BATCH_SIZE,\r\n",
        "                                             image_size=IMG_SIZE)\r\n",
        "\r\n",
        "validation_dataset = image_dataset_from_directory(input_path,\r\n",
        "                                             shuffle=True,\r\n",
        "                                             subset='validation',\r\n",
        "                                             seed=1,\r\n",
        "                                             validation_split=0.2,\r\n",
        "                                             batch_size=BATCH_SIZE,\r\n",
        "                                             image_size=IMG_SIZE)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 7553 files belonging to 3 classes.\n",
            "Using 6043 files for training.\n",
            "Found 7553 files belonging to 3 classes.\n",
            "Using 1510 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-wuyMjXCC2_"
      },
      "source": [
        "**There are a total of 32 batches of batch data in the verification set (one batch contains 32 images), and the 32 batches are divided into 26 and 6, 2 parts (verification and testing)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UN9BgBcCC_wE"
      },
      "source": [
        "**So now let's take a data, what we need and create test dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUMn3pIaDUBT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22f50832-0267-4142-899f-41f5adf3978b"
      },
      "source": [
        "validation_batches = tf.data.experimental.cardinality(validation_dataset)\r\n",
        "test_dataset = validation_dataset.take(validation_batches//validation_koef)\r\n",
        "validation_dataset = validation_dataset.skip(validation_batches//validation_koef)\r\n",
        "\r\n",
        "print(\"Done!\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0DXcEIwElUK"
      },
      "source": [
        "**Now let's configure the data for us.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ve5xzv3EnfJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fe8e246-0797-461d-876f-3e0d0a8b0a8d"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n",
        "\r\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\r\n",
        "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\r\n",
        "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\r\n",
        "\r\n",
        "print(\"Done!\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LoIcYfMFVh3"
      },
      "source": [
        "**Let's increase our data and change it a little. Very little))**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTs6V3FvFmKn"
      },
      "source": [
        "**First of make flip horizontally and vertically, spin, zoom, add contrast of each channel of each picture ,shifted up and down by 20%, left and right by 20%.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8-9G0dJFXm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "948ec56e-1ff9-4f67-db78-4e73b3acee22"
      },
      "source": [
        "data_change=tf.keras.Sequential([\r\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip(mode='horizontal'),\r\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\r\n",
        "    tf.keras.layers.experimental.preprocessing.RandomZoom(.5, .2),\r\n",
        "    tf.keras.layers.experimental.preprocessing.RandomContrast(factor=0.1),\r\n",
        "    tf.keras.layers.experimental.preprocessing.RandomTranslation(\r\n",
        "        height_factor=0.1, width_factor=0.1)\r\n",
        "])\r\n",
        "\r\n",
        "print(\"Done!\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ9cQNiCL09k"
      },
      "source": [
        "**Let's making the base model.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fin32O-L7S0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f67c8e3-4a94-433d-fe63-99b039dda8e2"
      },
      "source": [
        "base_model=tf.keras.applications.EfficientNetB0(input_shape=IMG_SIZE+(3,),\r\n",
        "                                    include_top=False,\r\n",
        "                                    weights='imagenet',\r\n",
        "                                    drop_connect_rate=0.4\r\n",
        "                                    )\r\n",
        "base_model.trainable=False\r\n",
        "model=tf.keras.Sequential()\r\n",
        "model.add(base_model)\r\n",
        "model.add(tf.keras.layers.GlobalAveragePooling2D())\r\n",
        "model.add(tf.keras.layers.Dense(1))\r\n",
        "\r\n",
        "print(model.summary())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "efficientnetb0 (Functional)  (None, 5, 5, 1280)        4049571   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 1281      \n",
            "=================================================================\n",
            "Total params: 4,050,852\n",
            "Trainable params: 1,281\n",
            "Non-trainable params: 4,049,571\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Sh7c_vwNMt8"
      },
      "source": [
        "**Good, all works. Now let's make some modification with layer(normalize, pooling, dense and drop some data).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVONt_j8NuSJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a40e58b-427a-43c5-c1d2-3060977e157a"
      },
      "source": [
        "input=tf.keras.Input(IMG_SIZE+(3,))\r\n",
        "x=base_model(data_change(input),\r\n",
        "             training=False)\r\n",
        "x=tf.keras.layers.GlobalAveragePooling2D()(x)\r\n",
        "x=tf.keras.layers.Dropout(0.2)(x)\r\n",
        "x=tf.keras.layers.BatchNormalization()(x)\r\n",
        "output=tf.keras.layers.Dense(1)(x)\r\n",
        "model=tf.keras.Model(input,output)\r\n",
        "\r\n",
        "print(model.summary())"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 160, 160, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 160, 160, 3)       0         \n",
            "_________________________________________________________________\n",
            "efficientnetb0 (Functional)  (None, 5, 5, 1280)        4049571   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_3 ( (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 1280)              5120      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 1281      \n",
            "=================================================================\n",
            "Total params: 4,055,972\n",
            "Trainable params: 3,841\n",
            "Non-trainable params: 4,052,131\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsVEkzziQAv1"
      },
      "source": [
        "**Now let's get down to optimization. We will optimize by Adam's method.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R10uHGltQRZ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c2f368-9f07-4286-f71f-d12a22b5838a"
      },
      "source": [
        "model.compile(optimizer='adam',\r\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "print(\"Done!\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLEt4nG-Qi_z"
      },
      "source": [
        "**And fit our model.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y65uHA1-QZ4k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9db1007-b40c-46b6-9192-78cbe5c8e63f"
      },
      "source": [
        "history=model.fit(train_dataset,\r\n",
        "          epochs=epochs,\r\n",
        "          validation_data=validation_dataset\r\n",
        "         )"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "189/189 [==============================] - 1906s 10s/step - loss: 0.3614 - accuracy: 0.8288 - val_loss: 0.0685 - val_accuracy: 0.9746\n",
            "Epoch 2/10\n",
            "189/189 [==============================] - 266s 1s/step - loss: 0.1639 - accuracy: 0.9347 - val_loss: 0.0417 - val_accuracy: 0.9828\n",
            "Epoch 3/10\n",
            "189/189 [==============================] - 266s 1s/step - loss: 0.1543 - accuracy: 0.9384 - val_loss: 0.0342 - val_accuracy: 0.9861\n",
            "Epoch 4/10\n",
            "189/189 [==============================] - 263s 1s/step - loss: 0.1305 - accuracy: 0.9504 - val_loss: 0.0361 - val_accuracy: 0.9836\n",
            "Epoch 5/10\n",
            "189/189 [==============================] - 262s 1s/step - loss: 0.1145 - accuracy: 0.9580 - val_loss: 0.0332 - val_accuracy: 0.9820\n",
            "Epoch 6/10\n",
            "189/189 [==============================] - 266s 1s/step - loss: 0.1133 - accuracy: 0.9522 - val_loss: 0.0325 - val_accuracy: 0.9861\n",
            "Epoch 7/10\n",
            "189/189 [==============================] - 262s 1s/step - loss: 0.1184 - accuracy: 0.9533 - val_loss: 0.0310 - val_accuracy: 0.9828\n",
            "Epoch 8/10\n",
            "189/189 [==============================] - 267s 1s/step - loss: 0.1326 - accuracy: 0.9455 - val_loss: 0.0333 - val_accuracy: 0.9853\n",
            "Epoch 9/10\n",
            "189/189 [==============================] - 265s 1s/step - loss: 0.1271 - accuracy: 0.9503 - val_loss: 0.0318 - val_accuracy: 0.9845\n",
            "Epoch 10/10\n",
            "189/189 [==============================] - 266s 1s/step - loss: 0.1141 - accuracy: 0.9547 - val_loss: 0.0292 - val_accuracy: 0.9877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoHqgZqAA3CD"
      },
      "source": [
        "**Let's save our model.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsHTltLzAorv",
        "outputId": "075eb504-a54f-408c-8e85-7a60be8038f7"
      },
      "source": [
        "wqe=model.evaluate(test_dataset)\r\n",
        "print(wqe)\r\n",
        "model.save('/content/drive/MyDrive')\r\n",
        "print(\"Done!\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 13s 1s/step - loss: 0.6880 - accuracy: 0.0056\n",
            "[0.7190898656845093, 0.0069444444961845875]\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/assets\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAxpk5bUMcUj"
      },
      "source": [
        ""
      ]
    }
  ]
}
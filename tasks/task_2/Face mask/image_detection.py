# -*- coding: utf-8 -*-
"""Image_Detection

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1adoAA2PjM_1yuEgiCkcFIg8m1Pu6RWWR
"""

from google.colab import drive
drive.mount('/content/gdrive')

PATH_TO_DATA = "/content/gdrive/MyDrive/data" 
!ls {PATH_TO_DATA}

import numpy as np 
import pandas as pd 
import os
import cv2

import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers

batch_size = 40
img_height = 200
img_width = 200

training_data = tf.keras.preprocessing.image_dataset_from_directory(
    PATH_TO_DATA,
    validation_split=0.3,
    subset= "training",
    seed=42,
    image_size= (img_height, img_width),
    batch_size=batch_size

)

testing_data = tf.keras.preprocessing.image_dataset_from_directory(
    PATH_TO_DATA,
    validation_split=0.3,
    subset= "validation",
    seed=42,
    image_size= (img_height, img_width),
    batch_size=batch_size

)

class_names = training_data.class_names

AUTOTUNE = tf.data.experimental.AUTOTUNE
training_data = training_data.cache().prefetch(buffer_size=AUTOTUNE)
testing_data = testing_data.cache().prefetch(buffer_size=AUTOTUNE)

model = tf.keras.models.Sequential([
  layers.experimental.preprocessing.Rescaling(1./255),
  layers.Conv2D(32, 3, activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(128, 3, activation='relu'),
  layers.MaxPooling2D(),
  layers.GlobalAveragePooling2D(),
  layers.Dense(256, activation='relu'),
  layers.Dense(2, activation= 'softmax')
])

model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])

ret = model.fit(training_data, validation_data= testing_data, epochs = 20)

plt.plot(ret.history['loss'], label = 'training loss')
plt.plot(ret.history['accuracy'], label = 'training accuracy')
plt.legend()
# -*- coding: utf-8 -*-
"""transfer_learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D6jeElG89lWDH-1F2bHo_q6PO2lZ2Rtu
"""

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers
from google.colab import files
from zipfile import ZipFile
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications import DenseNet169

file_name = 'face-mask-dataset.zip'

with ZipFile(file_name, 'r') as zip:
    zip.extractall()

batch_size = 40
img_height = 200
img_width = 200

train_data = tf.keras.preprocessing.image_dataset_from_directory(
    'data',
    validation_split=0.2,
    subset="training",
    seed=42,
    image_size=(img_height, img_width),
    batch_size=batch_size
)

test_data = tf.keras.preprocessing.image_dataset_from_directory(
    'data',
    validation_split=0.2,
    subset="validation",
    seed=42,
    image_size=(img_height, img_width),
    batch_size=batch_size
)

densenet_model = DenseNet169(weights='imagenet', include_top=False, input_shape=(200, 200, 3))

densenet_model.trainable = False

densenet_model.summary()

model = tf.keras.models.Sequential([
    densenet_model,
    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(1, activation='sigmoid')                                
])

model.summary()

model.compile(optimizer=Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])

model.fit(train_data, validation_data=test_data, epochs=5)

densenet_model.trainable = True
trainable = False
for layer in densenet_model.layers:
    if layer.name == 'conv1_block32':
        trainable = True
    layer.trainable = trainable

model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-5), metrics=['accuracy'])

model.fit(train_data, validation_data=test_data, epochs=5)